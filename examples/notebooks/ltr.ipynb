{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning to Rank Examples.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Ng-_HyW5LP",
        "colab_type": "text"
      },
      "source": [
        "# Terrier Learning to Rank Examples\n",
        "\n",
        "This notebook demonstrates the use of Pyterrier in a learning-to-rank fashion.\n",
        "\n",
        "## Preparation\n",
        "\n",
        "Lets install pyterrier, as usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eypl7XPrkifV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "e042ffb0-8ee5-4d95-c8bc-7e2895df541f"
      },
      "source": [
        "#!pip install python-terrier\n",
        "!pip install --upgrade git+https://github.com/terrier-org/pyterrier.git#egg=python-terrier"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-terrier\n",
            "  Cloning https://github.com/terrier-org/pyterrier.git to /tmp/pip-install-e2c_k3ze/python-terrier\n",
            "  Running command git clone -q https://github.com/terrier-org/pyterrier.git /tmp/pip-install-e2c_k3ze/python-terrier\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from python-terrier) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from python-terrier) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wget in /usr/local/lib/python3.6/dist-packages (from python-terrier) (3.2)\n",
            "Requirement already satisfied, skipping upgrade: pytrec_eval in /usr/local/lib/python3.6/dist-packages (from python-terrier) (0.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from python-terrier) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pyjnius~=1.3.0 in /usr/local/lib/python3.6/dist-packages (from python-terrier) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: matchpy in /usr/local/lib/python3.6/dist-packages (from python-terrier) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: sklearn in /usr/local/lib/python3.6/dist-packages (from python-terrier) (0.0)\n",
            "Requirement already satisfied, skipping upgrade: deprecation in /usr/local/lib/python3.6/dist-packages (from python-terrier) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: chest in /usr/local/lib/python3.6/dist-packages (from python-terrier) (0.2.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from python-terrier) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->python-terrier) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->python-terrier) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.6/dist-packages (from pyjnius~=1.3.0->python-terrier) (0.29.20)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: hopcroftkarp<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from matchpy->python-terrier) (1.2.5)\n",
            "Requirement already satisfied, skipping upgrade: multiset<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->python-terrier) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from deprecation->python-terrier) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: heapdict in /usr/local/lib/python3.6/dist-packages (from chest->python-terrier) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->python-terrier) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->deprecation->python-terrier) (2.4.7)\n",
            "Building wheels for collected packages: python-terrier\n",
            "  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-terrier: filename=python_terrier-0.3.0.dev0-cp36-none-any.whl size=37418 sha256=9fcedd75b4d85b9c026e34c93cd5c20167ed10636d545e3da9de41a545d003ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-75s589ez/wheels/cc/bb/69/836d846a92c787b35ca6478119c0033762ab2b95d866eeb288\n",
            "Successfully built python-terrier\n",
            "Installing collected packages: python-terrier\n",
            "  Found existing installation: python-terrier 0.3.0.dev0\n",
            "    Uninstalling python-terrier-0.3.0.dev0:\n",
            "      Successfully uninstalled python-terrier-0.3.0.dev0\n",
            "Successfully installed python-terrier-0.3.0.dev0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyterrier"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5thmTselkuBv",
        "colab_type": "text"
      },
      "source": [
        "## Init \n",
        "\n",
        "You must run pt.init() before other pyterrier functions and classes\n",
        "\n",
        "Arguments:    \n",
        "- `version` - terrier IR version e.g. \"5.2\"    \n",
        "- `mem` - megabytes allocated to java e.g. 4096"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPK5k4g2kkKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "  pt.init()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5BmNjqoXGow",
        "colab_type": "text"
      },
      "source": [
        "## Load Files and Index\n",
        "\n",
        "Again, lets focus on the small Vaswani test collection. Its easily accessible via the dataset API. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MCH20mGB8EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pt.datasets.get_dataset(\"vaswani\")\n",
        "\n",
        "indexref = dataset.get_index()\n",
        "topics = dataset.get_topics()\n",
        "qrels = dataset.get_qrels()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8hUuA_KKPUH",
        "colab_type": "text"
      },
      "source": [
        "## Multi-stage Retrieval\n",
        "\n",
        "In this experiment, we will be re-ranking the results obtaind from a BM25 ranking, by adding more features. Will then pass these for re-ranking by a regression technique, such as Random Forests.\n",
        "\n",
        "Conceptually, this pipeline has three stages:\n",
        "1. PL2 ranking\n",
        "2. Re-rank by each of the feaures (\"TF_IDF\" and \"PL2\")\n",
        "3. Apply the RandomForests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEjmsD3ya8Pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this ranker will make the candidate set of documents for each query\n",
        "BM25 = pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"BM25\"})\n",
        "\n",
        "#these rankers we will use to re-rank the BM25 results\n",
        "TF_IDF =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"TF_IDF\"})\n",
        "PL2 =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"PL2\"})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T07YF3-ULGsG",
        "colab_type": "text"
      },
      "source": [
        "OK, so how do we combine these?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTLh6SrCLGM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = BM25 >> (TF_IDF ** PL2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7M4cUxCLMTo",
        "colab_type": "text"
      },
      "source": [
        "Here, we are using two Pyterrer operators:\n",
        " - `>>` means \"then\", and takes the output documents of BM25 and puts them into the next stage. This means that TF_IDF and PL2 are ONLY applied on the documents that BM25 has identified.\n",
        " - `**` means feature-union - which makes each ranker into a feature in the `features` column of the results.\n",
        "\n",
        "Lets give a look at the output to see what it gives:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYNOf_TwLp0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "d9779320-58f8-4197-aa91-f05f7d05a8c5"
      },
      "source": [
        "pipe.transform(\"chemical end:2\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score</th>\n",
              "      <th>query</th>\n",
              "      <th>docid_x</th>\n",
              "      <th>rank_x</th>\n",
              "      <th>query_x</th>\n",
              "      <th>docid_y</th>\n",
              "      <th>rank_y</th>\n",
              "      <th>query_y</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10702</td>\n",
              "      <td>10703</td>\n",
              "      <td>0</td>\n",
              "      <td>13.472012</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>10702</td>\n",
              "      <td>0</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>10702</td>\n",
              "      <td>0</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>[7.38109017620895, 6.9992254918907575]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1055</td>\n",
              "      <td>1056</td>\n",
              "      <td>1</td>\n",
              "      <td>12.517082</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>1055</td>\n",
              "      <td>1</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>1055</td>\n",
              "      <td>1</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>[6.857899681644975, 6.358419229871986]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4885</td>\n",
              "      <td>4886</td>\n",
              "      <td>2</td>\n",
              "      <td>12.228161</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>4885</td>\n",
              "      <td>2</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>4885</td>\n",
              "      <td>2</td>\n",
              "      <td>chemical end:2</td>\n",
              "      <td>[6.69960466053696, 6.181368165774688]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  qid  docid  ...         query_y                                features\n",
              "0   1  10702  ...  chemical end:2  [7.38109017620895, 6.9992254918907575]\n",
              "1   1   1055  ...  chemical end:2  [6.857899681644975, 6.358419229871986]\n",
              "2   1   4885  ...  chemical end:2   [6.69960466053696, 6.181368165774688]\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZMvd3qjLkrs",
        "colab_type": "text"
      },
      "source": [
        "See, we now have a \"features\" column with numbers representing the TF_IDF and PL2 feature scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye6ZpcZaMBjT",
        "colab_type": "text"
      },
      "source": [
        "*A note about efficiency*: doing retrieval, then re-ranking the documents again can be slow. For this reason, Terrier has a FeaturesBatchRetrieve. Lets try this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gCHuDiJMNJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "cd0d5320-4d08-417a-d2dd-08e07f500793"
      },
      "source": [
        "fbr = pt.FeaturesBatchRetrieve(indexref, controls = {\"wmodel\": \"BM25\"}, features=[\"WMODEL:TF_IDF\", \"WMODEL:PL2\"]) \n",
        "#lets look at the top 2 results\n",
        "(fbr %2).transform(\"chemical\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>rank</th>\n",
              "      <th>docno</th>\n",
              "      <th>score</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10702</td>\n",
              "      <td>0</td>\n",
              "      <td>10703</td>\n",
              "      <td>13.472012</td>\n",
              "      <td>[7.38109017620895, 6.9992254918907575]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1055</td>\n",
              "      <td>1</td>\n",
              "      <td>1056</td>\n",
              "      <td>12.517082</td>\n",
              "      <td>[6.857899681644975, 6.358419229871986]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4885</td>\n",
              "      <td>2</td>\n",
              "      <td>4886</td>\n",
              "      <td>12.228161</td>\n",
              "      <td>[6.69960466053696, 6.181368165774688]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  qid  docid  rank  docno      score                                features\n",
              "0   1  10702     0  10703  13.472012  [7.38109017620895, 6.9992254918907575]\n",
              "1   1   1055     1   1056  12.517082  [6.857899681644975, 6.358419229871986]\n",
              "2   1   4885     2   4886  12.228161   [6.69960466053696, 6.181368165774688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo567qmCMZ41",
        "colab_type": "text"
      },
      "source": [
        "However, this kind of optimisation is common in Pyterrier, so Pyterrier actually supports automatic pipeline optimisation, using the `.compile()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmrnqg9YMpl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "70882fb4-8057-4014-ece8-899a593e4cd0"
      },
      "source": [
        "pipe_fast = pipe.compile()\n",
        "(pipe_fast %2).transform(\"chemical\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Applying 8 rules\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>rank</th>\n",
              "      <th>docno</th>\n",
              "      <th>score</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10702</td>\n",
              "      <td>0</td>\n",
              "      <td>10703</td>\n",
              "      <td>13.472012</td>\n",
              "      <td>[7.38109017620895, 6.9992254918907575]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1055</td>\n",
              "      <td>1</td>\n",
              "      <td>1056</td>\n",
              "      <td>12.517082</td>\n",
              "      <td>[6.857899681644975, 6.358419229871986]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4885</td>\n",
              "      <td>2</td>\n",
              "      <td>4886</td>\n",
              "      <td>12.228161</td>\n",
              "      <td>[6.69960466053696, 6.181368165774688]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  qid  docid  rank  docno      score                                features\n",
              "0   1  10702     0  10703  13.472012  [7.38109017620895, 6.9992254918907575]\n",
              "1   1   1055     1   1056  12.517082  [6.857899681644975, 6.358419229871986]\n",
              "2   1   4885     2   4886  12.228161   [6.69960466053696, 6.181368165774688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siS6M5t_hugs",
        "colab_type": "text"
      },
      "source": [
        "Finally, often we want our initial retrieval score to be a feature also. We can do this in one of two ways:\n",
        " - by adding a `SAMPLE` feature to FeaturesBatchRetrieve\n",
        " - or in the original feature-union definition, including an IdentityTransformer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXxeKfPXhuPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "25a8c80c-c277-476e-c243-7c6f9d5989cb"
      },
      "source": [
        "fbr = pt.FeaturesBatchRetrieve(indexref, controls = {\"wmodel\": \"BM25\"}, features=[\"SAMPLE\", \"WMODEL:TF_IDF\", \"WMODEL:PL2\"]) \n",
        "pipe = BM25 >> (pt.transformer.IdentityTransformer() ** TF_IDF ** PL2)\n",
        "\n",
        "(pipe %2).transform(\"chemical\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score_x</th>\n",
              "      <th>query</th>\n",
              "      <th>docid_x</th>\n",
              "      <th>rank_x</th>\n",
              "      <th>query_x</th>\n",
              "      <th>docid_y</th>\n",
              "      <th>rank_y</th>\n",
              "      <th>score_y</th>\n",
              "      <th>query_y</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10702</td>\n",
              "      <td>10703</td>\n",
              "      <td>0</td>\n",
              "      <td>13.472012</td>\n",
              "      <td>chemical</td>\n",
              "      <td>10702</td>\n",
              "      <td>0</td>\n",
              "      <td>chemical</td>\n",
              "      <td>10702</td>\n",
              "      <td>0</td>\n",
              "      <td>13.472012</td>\n",
              "      <td>chemical</td>\n",
              "      <td>[13.472012496423268, 7.38109017620895, 6.99922...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1055</td>\n",
              "      <td>1056</td>\n",
              "      <td>1</td>\n",
              "      <td>12.517082</td>\n",
              "      <td>chemical</td>\n",
              "      <td>1055</td>\n",
              "      <td>1</td>\n",
              "      <td>chemical</td>\n",
              "      <td>1055</td>\n",
              "      <td>1</td>\n",
              "      <td>12.517082</td>\n",
              "      <td>chemical</td>\n",
              "      <td>[12.517081895047532, 6.857899681644975, 6.3584...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4885</td>\n",
              "      <td>4886</td>\n",
              "      <td>2</td>\n",
              "      <td>12.228161</td>\n",
              "      <td>chemical</td>\n",
              "      <td>4885</td>\n",
              "      <td>2</td>\n",
              "      <td>chemical</td>\n",
              "      <td>4885</td>\n",
              "      <td>2</td>\n",
              "      <td>12.228161</td>\n",
              "      <td>chemical</td>\n",
              "      <td>[12.22816082084599, 6.69960466053696, 6.181368...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  qid  docid  ...   query_y                                           features\n",
              "0   1  10702  ...  chemical  [13.472012496423268, 7.38109017620895, 6.99922...\n",
              "1   1   1055  ...  chemical  [12.517081895047532, 6.857899681644975, 6.3584...\n",
              "2   1   4885  ...  chemical  [12.22816082084599, 6.69960466053696, 6.181368...\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R47HlFoMYAhi",
        "colab_type": "text"
      },
      "source": [
        "# Learning models and re-ranking\n",
        "\n",
        "Ok, lets get onto the actual machine learning. We can use standard Python ML techniques. We will demonstrate a few here, including from sci-kit learn and xgBoost.\n",
        "\n",
        "In each case, the pattern is the same:\n",
        " - Create a transformer that does the re-ranking\n",
        " - Call the fit() method on the created object with the training topics (and validation topics as necessary)\n",
        " - Evaluate the results with the Experiment function by using the test topics\n",
        "\n",
        " Firstly, lets separate our topics into train/validation/test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7r10lR3DvzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_topics, valid_topics, test_topics = np.split(topics, [int(.6*len(topics)), int(.8*len(topics))])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PYw_jasN6Vk",
        "colab_type": "text"
      },
      "source": [
        "## sci-kit learn RandomForestRegressor\n",
        "\n",
        "Our first learning-to-rank will be done using sci-kit learn's [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). \n",
        "\n",
        "We use `pt.piptlines.LTR_pipeline`, which is a pyterrier transformer that passes the document featuresÂ as \"X\" features to RandomForest. To learn the model (called fitting) the RandomForest, we invoke the `fit()` method - on the entire pipeline, specifying the queries (topics) and relevance assessment (qrels). The latter for the \"Y\" labels for the RandomForest fitting.\n",
        "\n",
        "NB: due to their bootstrap nature, Random Forests do not overfit, so we do not provide validation data to `fit()`.\n",
        "\n",
        "On the other hand, we could use any regression learner from sklearn, and adjust its parameters ourselves.\n",
        "\n",
        "Finally, we Experiment() on the test data to compare performances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YTI_ax4K19nl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "186b0de0-4793-4afc-c463-c9082a2129ec"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "BaselineLTR = fbr >> pt.pipelines.LTR_pipeline(RandomForestRegressor(n_estimators=400))\n",
        "BaselineLTR.fit(train_topics, qrels)\n",
        "\n",
        "results = pt.pipelines.Experiment([PL2, BaselineLTR], test_topics, qrels, [\"map\"], names=[\"PL2 Baseline\", \"LTR Baseline\"])\n",
        "results"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PL2 Baseline</td>\n",
              "      <td>0.206031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LTR Baseline</td>\n",
              "      <td>0.144980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name       map\n",
              "0  PL2 Baseline  0.206031\n",
              "1  LTR Baseline  0.144980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGw58PCuumuT",
        "colab_type": "text"
      },
      "source": [
        "## XgBoost Pipeline\n",
        "\n",
        "We now demonstrate the use of a LambdaMART implementation from [xgBoost](https://xgboost.readthedocs.io/en/latest/). Again, pyTerrier provides a transformer object, namely `XGBoostLTR_pipeline`, which takes in the constrcutor the actual xgBoost model that you want to train. We took the xgBoost configuration from [their example code](https://github.com/dmlc/xgboost/blob/master/demo/rank/rank.py).\n",
        "\n",
        "Call the `fit()` method on the full pipeline with the training and validation topics.\n",
        "\n",
        "Evaluate the results with the Experiment function by using the test topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM0r8EgFuGtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "params = {'objective': 'rank:ndcg', \n",
        "          'learning_rate': 0.1, \n",
        "          'gamma': 1.0, 'min_child_weight': 0.1,\n",
        "          'max_depth': 6,\n",
        "          'verbose': 2,\n",
        "          'random_state': 42 \n",
        "         }\n",
        "\n",
        "BaseLTR_LM = fbr >> pt.pipelines.XGBoostLTR_pipeline(xgb.sklearn.XGBRanker(**params))\n",
        "BaseLTR_LM.fit(train_topics, qrels, valid_topics, qrels)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVXoNhzSP-k2",
        "colab_type": "text"
      },
      "source": [
        "And evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn56DKZMTQ_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6688d85e-8599-4f11-db18-231abd0d7aee"
      },
      "source": [
        "allresultsLM = pt.pipelines.Experiment([PL2, BaseLTR_LM],\n",
        "                                test_topics,                                  \n",
        "                                qrels, [\"map\"], \n",
        "                                names=[\"PL2 Baseline\", \"LambdaMART\"])\n",
        "allresultsLM"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PL2 Baseline</td>\n",
              "      <td>0.206031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LambdaMART</td>\n",
              "      <td>0.204391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name       map\n",
              "0  PL2 Baseline  0.206031\n",
              "1    LambdaMART  0.204391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}